cleandf <- subset(cleandf, userCode != 138695)
#calculate mahalanobis distance
MD <- mahalanobis(cleandf[, c(22, 25, 27)], colMeans(cleandf[,c(22, 25, 27)]), cov(cleandf[, c(22, 25, 27)]))
#add mahalanobis distance to the data frame
cleandf$MD <- round(MD, 3)
#set threshhold to 10
cleandf$outlier_maha <- FALSE
cleandf$outlier_maha[cleandf$MD > 10] <- TRUE
#remove outliers
cleandf <- subset(cleandf, outlier_maha != TRUE)
#rank order education
cleandf$educationcode <- as.numeric(factor(cleandf$education, levels = c("No schooling completed", "Less than a high school diploma (GCSEs)", "High school degree or equivalent (A levels)", "Bachelor's degree", "Master's degree", "Doctorate degree")))
#calculate mahalanobis distance
MD <- mahalanobis(cleandf[, c(22, 25, 27)], colMeans(cleandf[,c(22, 25, 27)]), cov(cleandf[, c(22, 25, 27)]))
#add mahalanobis distance to the data frame
cleandf$MD <- round(MD, 3)
#set threshhold to 10
cleandf$outlier_maha <- FALSE
cleandf$outlier_maha[cleandf$MD > 10] <- TRUE
#remove outliers
cleandf <- subset(cleandf, outlier_maha != TRUE)
#rank order education
cleandf$educationcode <- as.numeric(factor(cleandf$education, levels = c("No schooling completed", "Less than a high school diploma (GCSEs)", "High school degree or equivalent (A levels)", "Bachelor's degree", "Master's degree", "Doctorate degree")))
#calculate mahalanobis distance
MD <- mahalanobis(cleandf[, c(22, 25, 27)], colMeans(cleandf[,c(22, 25, 27)]), cov(cleandf[, c(22, 25, 27)]))
#add mahalanobis distance to the data frame
cleandf$MD <- round(MD, 3)
#set threshhold to 10
cleandf$outlier_maha <- FALSE
cleandf$outlier_maha[cleandf$MD > 10] <- TRUE
#remove outliers
cleandf <- subset(cleandf, outlier_maha != TRUE)
#rank order education
cleandf$educationcode <- as.numeric(factor(cleandf$education, levels = c("No schooling completed", "Less than a high school diploma (GCSEs)", "High school degree or equivalent (A levels)", "Bachelor's degree", "Master's degree", "Doctorate degree")))
#calculate mahalanobis distance
MD <- mahalanobis(cleandf[, c(22, 25, 27)], colMeans(cleandf[,c(22, 25, 27)]), cov(cleandf[, c(22, 25, 27)]))
#add mahalanobis distance to the data frame
cleandf$MD <- round(MD, 3)
#set threshhold to 10
cleandf$outlier_maha <- FALSE
cleandf$outlier_maha[cleandf$MD > 10] <- TRUE
#remove outliers
cleandf <- subset(cleandf, outlier_maha != TRUE)
#rank order education
cleandf$educationcode <- as.numeric(factor(cleandf$education, levels = c("No schooling completed", "Less than a high school diploma (GCSEs)", "High school degree or equivalent (A levels)", "Bachelor's degree", "Master's degree", "Doctorate degree")))
#calculate mahalanobis distance
MD <- mahalanobis(cleandf[, c(22, 25, 27)], colMeans(cleandf[,c(22, 25, 27)]), cov(cleandf[, c(22, 25, 27)]))
#add mahalanobis distance to the data frame
cleandf$MD <- round(MD, 3)
#set threshhold to 10
cleandf$outlier_maha <- FALSE
cleandf$outlier_maha[cleandf$MD > 10] <- TRUE
#remove outliers
cleandf <- subset(cleandf, outlier_maha != TRUE)
#rank order education
cleandf$educationcode <- as.numeric(factor(cleandf$education, levels = c("No schooling completed", "Less than a high school diploma (GCSEs)", "High school degree or equivalent (A levels)", "Bachelor's degree", "Master's degree", "Doctorate degree")))
#calculate mahalanobis distance
MD <- mahalanobis(cleandf[, c(22, 25, 27)], colMeans(cleandf[,c(22, 25, 27)]), cov(cleandf[, c(22, 25, 27)]))
#add mahalanobis distance to the data frame
cleandf$MD <- round(MD, 3)
#set threshhold to 10
cleandf$outlier_maha <- FALSE
cleandf$outlier_maha[cleandf$MD > 10] <- TRUE
#remove outliers
cleandf <- subset(cleandf, outlier_maha != TRUE)
#calculate mahalanobis distance
MD <- mahalanobis(cleandf[, c(22, 25, 27)], colMeans(cleandf[,c(22, 25, 27)]), cov(cleandf[, c(22, 25, 27)]))
#add mahalanobis distance to the data frame
cleandf$MD <- round(MD, 3)
#set threshhold to 10
cleandf$outlier_maha <- FALSE
cleandf$outlier_maha[cleandf$MD > 10] <- TRUE
#remove outliers
cleandf <- subset(cleandf, outlier_maha != TRUE)
#calculate mahalanobis distance
MD <- mahalanobis(cleandf[, c(22, 25, 27)], colMeans(cleandf[,c(22, 25, 27)]), cov(cleandf[, c(22, 25, 27)]))
#add mahalanobis distance to the data frame
cleandf$MD <- round(MD, 3)
#set threshhold to 10
cleandf$outlier_maha <- FALSE
cleandf$outlier_maha[cleandf$MD > 10] <- TRUE
#remove outliers
cleandf <- subset(cleandf, outlier_maha != TRUE)
##########################################################
##                      CLEAN                           ##
##########################################################
#remove participants with missing data
preclean <- na.omit(preclean)
#ensure all numeric columns are numeric
preclean$Q17 <- as.numeric(preclean$Q17)
preclean$QID19 <- as.numeric(preclean$QID19)
preclean$Q2 <- as.numeric(preclean$Q2)
preclean$Q4 <- as.numeric(preclean$Q4)
preclean$Q5 <- as.numeric(preclean$Q5)
preclean$Q7 <- as.numeric(preclean$Q7)
preclean$Q8 <- as.numeric(preclean$Q8)
## REMOVE FRAUD RESPONSES ##
############################
#remove participants with reaction times lower than 200ms
cleandf <- subset(preclean, speed > 150)
cleandf <- subset(cleandf, congruent > 150)
cleandf <- subset(cleandf, incongruent > 150)
#remove participants with SR under 500
cleandf <- subset(cleandf, Q7 > 500)
#remove participants with weekly play time more than total
cleandf <- subset(cleandf, Q4 > Q5)
#remove participants with current SR higher than peak SR
cleandf <- subset(cleandf, Q7 >= Q8)
#remove responses indicating having started playing overwatch 7 or more years ago (the game is less than 6 years old)
cleandf <- subset(cleandf, (Q17 - Q2) <= 6)
#rename columns
cleandf <- cleandf %>%
rename(
gender = Q22,
age = Q17,
country = Q20,
race = Q26,
education = Q24,
SES = QID19,
ageoverwatch = Q2,
accounts = Q3,
totalhours = Q4,
weeklyhours = Q5,
class = Q6,
peaksr = Q7,
currentsr = Q8,
team = Q9,
aids = Q10,
level = Q16,
league = Q17.1
)
#remove specifically examined participants (removing participants with periods of rapid responses less than 50ms) and remove missing data (i.e. prefer not to say) - for loop does not work
cleandf <- subset(cleandf, userCode != 137329)
cleandf <- subset(cleandf, userCode != 138216)
cleandf <- subset(cleandf, userCode != 138241)
cleandf <- subset(cleandf, userCode != 138290)
cleandf <- subset(cleandf, userCode != 138368)
cleandf <- subset(cleandf, userCode != 138380)
cleandf <- subset(cleandf, userCode != 138520)
cleandf <- subset(cleandf, userCode != 138563)
cleandf <- subset(cleandf, userCode != 138694)
cleandf <- subset(cleandf, userCode != 138695)
#calculate mahalanobis distance
MD <- mahalanobis(cleandf[, c(22, 25, 27)], colMeans(cleandf[,c(22, 25, 27)]), cov(cleandf[, c(22, 25, 27)]))
#add mahalanobis distance to the data frame
cleandf$MD <- round(MD, 3)
#set threshhold to 10
cleandf$outlier_maha <- FALSE
cleandf$outlier_maha[cleandf$MD > 10] <- TRUE
#remove outliers
cleandf <- subset(cleandf, outlier_maha != TRUE)
#rank order education
cleandf$educationcode <- as.numeric(factor(cleandf$education, levels = c("No schooling completed", "Less than a high school diploma (GCSEs)", "High school degree or equivalent (A levels)", "Bachelor's degree", "Master's degree", "Doctorate degree")))
cleandf$zCSR <- (cleandf$currentsr - mean(cleandf$currentsr))/sd(cleandf$currentsr)
cleandf$zCSR2 <- scale(cleandf$currentsr, true, true)
##########################################################
##                      PRELIMINARIES                   ##
##########################################################
set.seed(1234321)
library(tidyverse)
library(corrplot)
library(pastecs)
# clear workspace
rm(list=ls())
##########################################################
##                  SET WORK ENVIRONMENT                ##
##########################################################
# set general folder
workspace = getwd()
# set name of script with functions
funScript = "overwatch_funs.R"
# load functions into workspace
source(paste(workspace, funScript, sep = "/"))
# set names of folders for input and output files, set output filename
inputFolder = paste(workspace, "input", sep = "/")
outputFolder = paste(workspace, "output", sep = "/")
# set data input folder as default location of input files
setwd(inputFolder)
cleandf$zCSR <- (cleandf$currentsr - mean(cleandf$currentsr))/sd(cleandf$currentsr)
cleandf$zCSR2 <- scale(cleandf$currentsr, true, true)
# unzip and merge all data
source(paste(workspace, "overwatch_01_merge.R", sep = "/"))
# aggregate data
source(paste(workspace, "overwatch_02_aggregate.R", sep = "/"))
#combine questionnaire and task data
source(paste(workspace, "overwatch_03_combine.R", sep = "/"))
#clean dataframe
source(paste(workspace, "overwatch_04_clean.R", sep = "/"))
#run analysis
source(paste(workspace, "overwatch_05_analysis.R", sep = "/"))
cleandf$zCSR <- (cleandf$currentsr - mean(cleandf$currentsr))/sd(cleandf$currentsr)
cleandf$zCSR2 <- scale(cleandf$currentsr, true, true)
cleandf$zCSR2 <- scale(cleandf$currentsr, true, true)
cleandf$zCSR2 <- scale(cleandf$currentsr, true, true)
cleandf$zEDU <- (cleandf$educationcode - mean(cleandf$educationcode))/sd(cleandf$educationcode)
cleandf$zCSR <- (cleandf$currentsr - mean(cleandf$currentsr))/sd(cleandf$currentsr)
cleandf$zage <- (cleandf$age - mean(cleandf$age))/sd(cleandf$age)
cleandf$zSES <- (cleandf$SES - mean(cleandf$SES))/sd(cleandf$SES)
cleandf$zEDU <- (cleandf$educationcode - mean(cleandf$educationcode))/sd(cleandf$educationcode)
cleandf$zTH <- (cleandf$totalhours - mean(cleandf$totalhours))/sd(cleandf$totalhours)
View(preclean)
##########################################################
##                      CLEAN                           ##
##########################################################
#remove participants with missing data
preclean <- na.omit(preclean)
#ensure all numeric columns are numeric
preclean$Q17 <- as.numeric(preclean$Q17)
preclean$QID19 <- as.numeric(preclean$QID19)
preclean$Q2 <- as.numeric(preclean$Q2)
preclean$Q4 <- as.numeric(preclean$Q4)
preclean$Q5 <- as.numeric(preclean$Q5)
preclean$Q7 <- as.numeric(preclean$Q7)
preclean$Q8 <- as.numeric(preclean$Q8)
#ensure factor columns are factors
preclean$Q17.1 <- as.factor(preclean$Q17.1)
preclean$Q16 <- as.numeric(preclean$Q16)
## REMOVE FRAUD RESPONSES ##
############################
#remove participants with reaction times lower than 200ms
cleandf <- subset(preclean, speed > 150)
cleandf <- subset(cleandf, congruent > 150)
cleandf <- subset(cleandf, incongruent > 150)
#remove participants with SR under 500
cleandf <- subset(cleandf, Q7 > 500)
#remove participants with weekly play time more than total
cleandf <- subset(cleandf, Q4 > Q5)
#remove participants with current SR higher than peak SR
cleandf <- subset(cleandf, Q7 >= Q8)
#remove responses indicating having started playing overwatch 7 or more years ago (the game is less than 6 years old)
cleandf <- subset(cleandf, (Q17 - Q2) <= 6)
#rename columns
cleandf <- cleandf %>%
rename(
gender = Q22,
age = Q17,
country = Q20,
race = Q26,
education = Q24,
SES = QID19,
ageoverwatch = Q2,
accounts = Q3,
totalhours = Q4,
weeklyhours = Q5,
class = Q6,
peaksr = Q7,
currentsr = Q8,
team = Q9,
aids = Q10,
level = Q16,
league = Q17.1
)
#remove specifically examined participants (removing participants with periods of rapid responses less than 50ms) and remove missing data (i.e. prefer not to say) - for loop does not work
cleandf <- subset(cleandf, userCode != 137329)
cleandf <- subset(cleandf, userCode != 138216)
cleandf <- subset(cleandf, userCode != 138241)
cleandf <- subset(cleandf, userCode != 138290)
cleandf <- subset(cleandf, userCode != 138368)
cleandf <- subset(cleandf, userCode != 138380)
cleandf <- subset(cleandf, userCode != 138520)
cleandf <- subset(cleandf, userCode != 138563)
cleandf <- subset(cleandf, userCode != 138694)
cleandf <- subset(cleandf, userCode != 138695)
#calculate mahalanobis distance
MD <- mahalanobis(cleandf[, c(22, 25, 27)], colMeans(cleandf[,c(22, 25, 27)]), cov(cleandf[, c(22, 25, 27)]))
#add mahalanobis distance to the data frame
cleandf$MD <- round(MD, 3)
#set threshhold to 10
cleandf$outlier_maha <- FALSE
cleandf$outlier_maha[cleandf$MD > 10] <- TRUE
#remove outliers
cleandf <- subset(cleandf, outlier_maha != TRUE)
#rank order education
cleandf$educationcode <- as.numeric(factor(cleandf$education, levels = c("No schooling completed", "Less than a high school diploma (GCSEs)", "High school degree or equivalent (A levels)", "Bachelor's degree", "Master's degree", "Doctorate degree")))
#z transform predictor variables
cleandf$zCSR <- (cleandf$currentsr - mean(cleandf$currentsr))/sd(cleandf$currentsr)
cleandf$zage <- (cleandf$age - mean(cleandf$age))/sd(cleandf$age)
cleandf$zSES <- (cleandf$SES - mean(cleandf$SES))/sd(cleandf$SES)
cleandf$zEDU <- (cleandf$educationcode - mean(cleandf$educationcode))/sd(cleandf$educationcode)
cleandf$zTH <- (cleandf$totalhours - mean(cleandf$totalhours))/sd(cleandf$totalhours)
#proficiency evidence
PROFlm <- lm(currentsr ~ totalhours + level + league, data=cleandf)
summary(PROFlm)
#proficiency evidence
PROFlm <- lm(currentsr ~ zTH + level + league, data=cleandf)
summary(PROFlm)
View(cleandf)
table(cleandf$gender)
cleandf$zAGE <- (cleandf$age - mean(cleandf$age))/sd(cleandf$age)
UPDlm <- lm(updatingaccuracy ~ zCSR + zAGE + zSES + zEDU, data=cleandf)
summary(UPDlm)
#inhibition regression
INHlm <- lm(RTinterference ~ currentsr + age + SES + educationcode, data=cleandf)
summary(INHlm)
INHlm <- lm(RTinterference ~ zCSR + zAGE + zSES + zEDU, data=cleandf)
summary(INHlm)
NOCUPDlm <- lm(updatingaccuracy ~ zCSR, data=cleandf)
summary(NOCUPDlm)
tankdf <- subset(cleandf, class == "Tank")
supportdf <- subset(cleandf, class == "Support")
damagedf <- subset(cleandf, class == "Damage")
SSHIlm <- lm(switchCosts ~ zCSR + zAGE + zSES + zEDU, data=supportdf)
summary(SSHIlm)
#updating regression
SUPDlm <- lm(updatingaccuracy ~ zCSR + zAGE + zSES + zEDU, data=supportdf)
summary(SUPDlm)
#updating regression
DUPDlm <- lm(updatingaccuracy ~ zCSR + zAGE + zSES + zEDU, data=damagedf)
summary(DUPDlm)
#descriptive statistics
stat.desc(cleandf)
#correlation matrix
cormat <- cleandf %>% select(3, 8, 9, 11, 12, 14, 15, 22, 25, 27, 30)
source("http://www.sthda.com/upload/rquery_cormat.r")
rquery.cormat(cormat, type="upper")
stat.desc(cleandf)
PROFlm <- lm(currentsr ~ zTH + level + league, data=cleandf)
summary(PROFlm)
PROFlm <- lm(currentsr ~ zTH + level + league, data=cleandf)
summary(PROFlm)
PROFlm <- lm(currentsr ~ zTH + level + league, data=cleandf)
summary(PROFlm)
PROFlm <- lm(currentsr ~ zTH + level + league, data=cleandf)
##########################################################
##                      CLEAN                           ##
##########################################################
#remove participants with missing data
preclean <- na.omit(preclean)
#ensure all numeric columns are numeric
preclean$Q17 <- as.numeric(preclean$Q17)
preclean$QID19 <- as.numeric(preclean$QID19)
preclean$Q2 <- as.numeric(preclean$Q2)
preclean$Q4 <- as.numeric(preclean$Q4)
preclean$Q5 <- as.numeric(preclean$Q5)
preclean$Q7 <- as.numeric(preclean$Q7)
preclean$Q8 <- as.numeric(preclean$Q8)
## REMOVE FRAUD RESPONSES ##
############################
#remove participants with reaction times lower than 200ms
cleandf <- subset(preclean, speed > 150)
cleandf <- subset(cleandf, congruent > 150)
cleandf <- subset(cleandf, incongruent > 150)
#remove participants with SR under 500
cleandf <- subset(cleandf, Q7 > 500)
#remove participants with weekly play time more than total
cleandf <- subset(cleandf, Q4 > Q5)
#remove participants with current SR higher than peak SR
cleandf <- subset(cleandf, Q7 >= Q8)
#remove responses indicating having started playing overwatch 7 or more years ago (the game is less than 6 years old)
cleandf <- subset(cleandf, (Q17 - Q2) <= 6)
#rename columns
cleandf <- cleandf %>%
rename(
gender = Q22,
age = Q17,
country = Q20,
race = Q26,
education = Q24,
SES = QID19,
ageoverwatch = Q2,
accounts = Q3,
totalhours = Q4,
weeklyhours = Q5,
class = Q6,
peaksr = Q7,
currentsr = Q8,
team = Q9,
aids = Q10,
level = Q16,
league = Q17.1
)
#remove specifically examined participants (removing participants with periods of rapid responses less than 50ms) and remove missing data (i.e. prefer not to say) - for loop does not work
cleandf <- subset(cleandf, userCode != 137329)
cleandf <- subset(cleandf, userCode != 138216)
cleandf <- subset(cleandf, userCode != 138241)
cleandf <- subset(cleandf, userCode != 138290)
cleandf <- subset(cleandf, userCode != 138368)
cleandf <- subset(cleandf, userCode != 138380)
cleandf <- subset(cleandf, userCode != 138520)
cleandf <- subset(cleandf, userCode != 138563)
cleandf <- subset(cleandf, userCode != 138694)
cleandf <- subset(cleandf, userCode != 138695)
#calculate mahalanobis distance
MD <- mahalanobis(cleandf[, c(22, 25, 27)], colMeans(cleandf[,c(22, 25, 27)]), cov(cleandf[, c(22, 25, 27)]))
#add mahalanobis distance to the data frame
cleandf$MD <- round(MD, 3)
#set threshhold to 10
cleandf$outlier_maha <- FALSE
cleandf$outlier_maha[cleandf$MD > 10] <- TRUE
#remove outliers
cleandf <- subset(cleandf, outlier_maha != TRUE)
#rank order education
cleandf$educationcode <- as.numeric(factor(cleandf$education, levels = c("No schooling completed", "Less than a high school diploma (GCSEs)", "High school degree or equivalent (A levels)", "Bachelor's degree", "Master's degree", "Doctorate degree")))
#load the data from the questionnaire
rawq = read.csv("questionnaire/overwatch_project.csv")
#delete unneeded columns
cleanq <- rawq %>% select(7, 18:32, 58:60)
#delete unneeded rows
cleanq <- cleanq[-c(1, 2),]
#delete incomplete forms
cleanq <- cleanq[!(cleanq$Finished == FALSE),]
#rename sessiontoken to match aggShiftingData
colnames(cleanq)[colnames(cleanq) == "sessiontoken"] <- "sessionToken"
#combine data from questionnaires and tasks
df <- merge(cleanq, aggInhibitionData, by = "sessionToken", all = TRUE)
df1 <- merge(df, aggShiftingData, by = "sessionToken", all = TRUE)
preclean <- merge(df1, aggUpdatingData, by = "sessionToken", all = TRUE)
preclean <- preclean[, !(names(preclean) %in% c("userCode.y", "userCode.x"))]
#remove participants with missing data
preclean <- na.omit(preclean)
#ensure all numeric columns are numeric
preclean$Q17 <- as.numeric(preclean$Q17)
preclean$QID19 <- as.numeric(preclean$QID19)
preclean$Q2 <- as.numeric(preclean$Q2)
preclean$Q4 <- as.numeric(preclean$Q4)
preclean$Q5 <- as.numeric(preclean$Q5)
preclean$Q7 <- as.numeric(preclean$Q7)
preclean$Q8 <- as.numeric(preclean$Q8)
#remove participants with reaction times lower than 200ms
cleandf <- subset(preclean, speed > 150)
cleandf <- subset(cleandf, congruent > 150)
cleandf <- subset(cleandf, incongruent > 150)
#remove participants with SR under 500
cleandf <- subset(cleandf, Q7 > 500)
#remove participants with weekly play time more than total
cleandf <- subset(cleandf, Q4 > Q5)
#remove participants with current SR higher than peak SR
cleandf <- subset(cleandf, Q7 >= Q8)
#remove responses indicating having started playing overwatch 7 or more years ago (the game is less than 6 years old)
cleandf <- subset(cleandf, (Q17 - Q2) <= 6)
#rename columns
cleandf <- cleandf %>%
rename(
gender = Q22,
age = Q17,
country = Q20,
race = Q26,
education = Q24,
SES = QID19,
ageoverwatch = Q2,
accounts = Q3,
totalhours = Q4,
weeklyhours = Q5,
class = Q6,
peaksr = Q7,
currentsr = Q8,
team = Q9,
aids = Q10,
level = Q16,
league = Q17.1
)
#remove specifically examined participants (removing participants with periods of rapid responses less than 50ms) and remove missing data (i.e. prefer not to say) - for loop does not work
cleandf <- subset(cleandf, userCode != 137329)
cleandf <- subset(cleandf, userCode != 138216)
cleandf <- subset(cleandf, userCode != 138241)
cleandf <- subset(cleandf, userCode != 138290)
cleandf <- subset(cleandf, userCode != 138368)
cleandf <- subset(cleandf, userCode != 138380)
cleandf <- subset(cleandf, userCode != 138520)
cleandf <- subset(cleandf, userCode != 138563)
cleandf <- subset(cleandf, userCode != 138694)
cleandf <- subset(cleandf, userCode != 138695)
#calculate mahalanobis distance
MD <- mahalanobis(cleandf[, c(22, 25, 27)], colMeans(cleandf[,c(22, 25, 27)]), cov(cleandf[, c(22, 25, 27)]))
#add mahalanobis distance to the data frame
cleandf$MD <- round(MD, 3)
#set threshhold to 10
cleandf$outlier_maha <- FALSE
cleandf$outlier_maha[cleandf$MD > 10] <- TRUE
#remove outliers
cleandf <- subset(cleandf, outlier_maha != TRUE)
#rank order education
cleandf$educationcode <- as.numeric(factor(cleandf$education, levels = c("No schooling completed", "Less than a high school diploma (GCSEs)", "High school degree or equivalent (A levels)", "Bachelor's degree", "Master's degree", "Doctorate degree")))
PROFlm <- lm(currentsr ~ zTH + level + league, data=cleandf)
#z transform predictor variables
cleandf$zCSR <- (cleandf$currentsr - mean(cleandf$currentsr))/sd(cleandf$currentsr)
cleandf$zAGE <- (cleandf$age - mean(cleandf$age))/sd(cleandf$age)
cleandf$zSES <- (cleandf$SES - mean(cleandf$SES))/sd(cleandf$SES)
cleandf$zEDU <- (cleandf$educationcode - mean(cleandf$educationcode))/sd(cleandf$educationcode)
cleandf$zTH <- (cleandf$totalhours - mean(cleandf$totalhours))/sd(cleandf$totalhours)
PROFlm <- lm(currentsr ~ zTH + level + league, data=cleandf)
summary(PROFlm)
#updating regression
UPDlm <- lm(updatingaccuracy ~ zCSR + zAGE + zSES + zEDU, data=cleandf)
summary(UPDlm)
INHlm <- lm(RTinterference ~ zCSR + zAGE + zSES + zEDU, data=cleandf)
summary(INHlm)
#updating regression
UPDlm <- lm(updatingaccuracy ~ zCSR + zAGE + zSES + zEDU, data=cleandf)
summary(UPDlm)
#inhibition regression
INHlm <- lm(RTinterference ~ zCSR + zAGE + zSES + zEDU, data=cleandf)
summary(INHlm)
#shifting regression
SHIlm <- lm(switchCosts ~ zCSR + zAGE + zSES + zEDU, data=cleandf)
summary(SHIlm)
#updating regression
UPDlm <- lm(updatingaccuracy ~ zCSR + zAGE + zSES + zEDU, data=cleandf)
summary(UPDlm)
#inhibition regression
INHlm <- lm(RTinterference ~ zCSR + zAGE + zSES + zEDU, data=cleandf)
summary(INHlm)
#shifting regression
SHIlm <- lm(switchCosts ~ zCSR + zAGE + zSES + zEDU, data=cleandf)
summary(SHIlm)
#updating regression
NOCUPDlm <- lm(updatingaccuracy ~ zCSR, data=cleandf)
summary(NOCUPDlm)
NOCINHlm <- lm(RTinterference ~ zCSR, data=cleandf)
summary(NOCINHlm)
NOCSHIlm <- lm(switchCosts ~ zCSR, data=cleandf)
summary(NOCSHIlm)
